{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Lib"
      ],
      "metadata": {
        "id": "cuJj5qKDHgy0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "twub6oM1Nfxf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch torchvision timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C6hOBIlNi9u"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip dataset"
      ],
      "metadata": {
        "id": "1YjwNGTeHjzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHnfEKimOYpA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "unzip all.zip -d datasetss/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "init wanb for logging"
      ],
      "metadata": {
        "id": "sY-EvueSHmfE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKMSDv2gm6pp"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"resnet101-training-project\", name=\"all-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define dataset paths (Update this to match your folder structure)"
      ],
      "metadata": {
        "id": "iqA0EmATHu00"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yusGyzXqOHUO"
      },
      "outputs": [],
      "source": [
        "# Define dataset paths (Update this to match your folder structure)\n",
        "data_dir = '/content/datasetss'  # Update with your dataset path\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define transformations for data augmentation"
      ],
      "metadata": {
        "id": "pWbRra5rHwqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "N9X8d7DsO6J4"
      },
      "outputs": [],
      "source": [
        "# Define transformations for data augmentation\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load datasets"
      ],
      "metadata": {
        "id": "E0U7Be1dHyJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QGueujx3O75U"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=transform['train'])\n",
        "val_dataset = ImageFolder(val_dir, transform=transform['val'])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained ResNet101 model"
      ],
      "metadata": {
        "id": "p3NXv0UEH5H6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsd5JgeSRYfo",
        "outputId": "5daa17d5-feb1-4d9b-d494-0b7eb8e72309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet101 model\n",
        "model = models.resnet101(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)  # Get number of classes from dataset\n",
        "\n",
        "# Modify the final layer to match our number of classes\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),  # Dropout Layer added (30% dropout)\n",
        "    nn.Linear(model.fc.in_features, num_classes)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define loss function and optimizer"
      ],
      "metadata": {
        "id": "ymRn6_bYH8ak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9cc7Cfj3RkEu"
      },
      "outputs": [],
      "source": [
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop with best model saving"
      ],
      "metadata": {
        "id": "ehaVdjixICtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pa4NOHERRnpg"
      },
      "outputs": [],
      "source": [
        "# Training loop with best model saving\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
        "    best_val_acc = 0.0\n",
        "    best_model_path = '/content/fruit.pth'\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_acc = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch+1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc\n",
        "        })\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Best model saved with accuracy: {best_val_acc:.2f}%\")\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "    print(\"Training complete!\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "kA7z5yXHIEkg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKoPqwWDSFmH",
        "outputId": "71181b92-506e-4d05-b99a-df743d562074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 | Train Loss: 0.0955 | Train Acc: 97.00% | Val Loss: 0.0653 | Val Acc: 98.27%\n",
            "Best model saved with accuracy: 98.27%\n",
            "Training complete!\n",
            "Best model saved at /content/fruit.pth\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1)\n",
        "\n",
        "print(f'Best model saved at /content/fruit.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3ba1uFSvqxm"
      },
      "source": [
        "HOW TO CALL MY MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load trained model and class"
      ],
      "metadata": {
        "id": "Uvdhf0SRIMTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTw3zoWxthJj",
        "outputId": "1e541eb7-be4f-4f9d-b010-4ac3e67f4b60",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-ed3d3772604e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/fruit.pth', map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load class names (make sure they match your dataset)\n",
        "class_names = [\"good\", \"rotten\"]  # Update with your actual class names\n",
        "\n",
        "# Load trained model\n",
        "num_classes = len(class_names)\n",
        "model = models.resnet101(pretrained=False)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/fruit.pth', map_location=torch.device('cpu')))\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(\"Model Loaded Successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define image transformation (Same as training)"
      ],
      "metadata": {
        "id": "M-qbNkqJIKOr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "qdiyAwpStxxV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define image transformation (Same as training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the class and confidence score for an image."
      ],
      "metadata": {
        "id": "2Ymzn_vJIRHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path):\n",
        "    \"\"\"Predict the class and confidence score for an image.\"\"\"\n",
        "    image = Image.open(image_path)  # Load image\n",
        "    image = transform(image).unsqueeze(0)  # Apply transformations and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)  # Forward pass\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted_class = torch.max(probabilities, 1)  # Get top class and confidence\n",
        "\n",
        "    predicted_label = class_names[predicted_class.item()]  # Get class name\n",
        "    confidence_percentage = confidence.item() * 100  # Convert confidence to percentage\n",
        "\n",
        "    return predicted_label, confidence_percentage"
      ],
      "metadata": {
        "id": "NmtjdPsNj6sX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "call the function to predict the image from a folder"
      ],
      "metadata": {
        "id": "M5sqxoDXIa5K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOA3pRchMahj",
        "outputId": "da3290fb-a04f-41e8-eec0-6dcd0881d35c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: starfruit_1739689948669.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.48%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946826.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.74%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945084.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.76%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946445.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.30%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947264.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.91%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943731.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.23%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945874.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.57%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946447.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946635.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.28%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948453.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.79%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944052.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 88.78%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948137.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.83%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944367.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.94%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945582.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.66%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948452.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.55%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948567.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947266.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.95%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944365.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.36%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948139.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.88%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943735.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.66%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947915.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 88.84%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947587.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.87%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944480.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944259.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.52%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947372.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.85%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945680.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 90.43%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944049.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.12%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947696.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.67%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945584.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.78%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945089.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.90%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947484.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.95%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945485.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.81%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946256.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.89%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944477.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.80%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944261.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.88%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943471.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947694.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.91%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944989.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.87%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943733.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.86%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946542.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.23%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948348.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.46%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946069.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 95.75%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947799.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.84%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945481.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947691.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.84%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944887.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.58%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948245.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.55%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944152.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 97.55%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945779.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946258.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.67%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948141.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 69.86%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945683.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.70%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943628.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.45%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946166.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.98%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943473.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.53%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945479.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.81%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946063.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.84%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944986.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.84%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944575.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943468.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.25%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947159.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.30%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944984.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.95%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946449.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947585.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945380.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.99%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944370.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.89%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944780.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.71%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946830.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.37%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944578.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.85%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944786.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.91%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944883.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.90%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946828.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.89%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943836.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.76%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948447.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.14%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944156.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.39%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946065.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944681.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946067.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944154.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.47%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946164.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.62%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945878.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.78%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944475.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.94%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947374.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.58%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944473.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.98%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943937.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946351.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.73%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945278.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.97%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948572.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.29%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948569.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.20%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946354.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.83%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944991.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.93%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945181.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.85%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947486.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.41%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947582.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.86%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944047.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.95%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944580.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.89%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946941.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.25%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946823.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.93%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944782.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.49%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948022.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.94%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948671.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.90%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945087.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945876.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.95%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947698.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.28%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944784.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.36%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947271.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.86%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943729.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944885.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.57%\n",
            "------------------------------\n",
            "Image: starfruit_1739689944582.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948352.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.02%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946160.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.94%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945483.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.88%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945973.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.57%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948134.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.11%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947797.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 97.58%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946633.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.97%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948450.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.89%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947046.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.98%\n",
            "------------------------------\n",
            "Image: starfruit_1739689943626.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.60%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945775.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.96%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947268.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 96.92%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945777.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.50%\n",
            "------------------------------\n",
            "Image: starfruit_1739689945183.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.76%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947156.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 98.47%\n",
            "------------------------------\n",
            "Image: starfruit_1739689946162.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.91%\n",
            "------------------------------\n",
            "Image: starfruit_1739689947376.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.93%\n",
            "------------------------------\n",
            "Image: starfruit_1739689948350.jpg\n",
            "Predicted Class: good\n",
            "Confidence Score: 99.16%\n",
            "------------------------------\n",
            "Predictions saved to /content/prediction_results.txt\n"
          ]
        }
      ],
      "source": [
        "image_folder = \"/content/dataset/starfruit\"  # Change to your folder path\n",
        "output_results = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith((\".jpg\", \".png\", \".jpeg\")):  # Ensure it's an image file\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        predicted_label, confidence_percentage = predict(image_path)\n",
        "        output_results.append((filename, predicted_label, confidence_percentage))\n",
        "\n",
        "        print(f\"Image: {filename}\")\n",
        "        print(f\"Predicted Class: {predicted_label}\")\n",
        "        print(f\"Confidence Score: {confidence_percentage:.2f}%\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "# Optionally save results to a file\n",
        "output_file = \"/content/prediction_results.txt\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    for filename, label, confidence in output_results:\n",
        "        f.write(f\"{filename}: {label} ({confidence:.2f}%)\\n\")\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "udJZIOl3Ig84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uzkLZslslMiJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "unzip bad_fruits_roi.zip -d datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KQ8NG4-6Q26b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "unzip good_fruits_roi.zip -d dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Report"
      ],
      "metadata": {
        "id": "mtNjmn08ImE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Ensure model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Define image folder (where images are stored)\n",
        "image_folder = \"/content/datasetss/valid\"  # Adjust this path\n",
        "\n",
        "# Manually define class names\n",
        "class_names = [\"good\", \"rotten\"]  # Ensure these match your dataset structure\n",
        "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
        "print(class_to_idx)\n",
        "# Define loss function (same as training)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "total_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_images = 0\n",
        "\n",
        "def predict(image_path, true_label_idx):\n",
        "    \"\"\"Predict the class and confidence score for an image while computing loss.\"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Move image to same device as model\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)  # Model is on the same device\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted_class = torch.max(probabilities, 1)\n",
        "        print(true_label_idx)\n",
        "        # Move true label to the same device before computing loss\n",
        "        true_label_tensor = torch.tensor([true_label_idx], device=device)\n",
        "        loss = criterion(outputs, true_label_tensor)\n",
        "\n",
        "    predicted_label = class_names[predicted_class.item()]\n",
        "    confidence_percentage = confidence.item() * 100\n",
        "    return predicted_label, confidence_percentage, loss.item(), predicted_class.item()\n",
        "\n",
        "# Process all images\n",
        "output_results = []\n",
        "\n",
        "for class_folder in class_names:  # Iterate over predefined class names\n",
        "    class_folder_path = os.path.join(image_folder, class_folder)\n",
        "    if not os.path.isdir(class_folder_path):  # Skip if not a valid directory\n",
        "        print(f\"Warning: Folder not found - {class_folder_path}\")\n",
        "        continue\n",
        "\n",
        "    for filename in os.listdir(class_folder_path):\n",
        "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            image_path = os.path.join(class_folder_path, filename)\n",
        "\n",
        "            # Predict label and compute loss\n",
        "            predicted_label, confidence_percentage, loss, predicted_idx = predict(image_path, class_to_idx[class_folder])\n",
        "\n",
        "            # Store true and predicted labels\n",
        "            true_labels.append(class_to_idx[class_folder])  # Store true labels as indices\n",
        "            predicted_labels.append(class_to_idx[predicted_label])\n",
        "\n",
        "            # Update test loss and accuracy calculations\n",
        "            total_loss += loss\n",
        "            total_images += 1\n",
        "            if predicted_idx == class_to_idx[class_folder]:  # Check if prediction is correct\n",
        "                correct_predictions += 1\n",
        "\n",
        "            output_results.append((filename, class_folder, predicted_label, confidence_percentage, loss))\n",
        "\n",
        "            print(f\"Image: {filename} | True: {class_folder} | Predicted: {predicted_label} | Confidence: {confidence_percentage:.2f}% | Loss: {loss:.4f}\")\n",
        "\n",
        "# Check if true_labels and predicted_labels are populated\n",
        "if not true_labels or not predicted_labels:\n",
        "    raise ValueError(\"No labels were detected. Ensure images are inside 'good/' and 'rotten/' subfolders.\")\n",
        "\n",
        "# Compute Test Loss and Test Accuracy\n",
        "test_loss = total_loss / total_images\n",
        "test_accuracy = (correct_predictions / total_images) * 100\n",
        "\n",
        "# Save results to file\n",
        "output_file = \"/content/prediction_results.txt\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    for filename, true_label, predicted_label, confidence, loss in output_results:\n",
        "        f.write(f\"{filename}: True: {true_label}, Predicted: {predicted_label} ({confidence:.2f}%) | Loss: {loss:.4f}\\n\")\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")\n",
        "\n",
        "# Generate and print classification report\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "print(\"Class Names Mapping:\", class_to_idx)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kZbW_CanYC_M",
        "outputId": "5f5cc125-6719-4c65-e24d-c0cdefcca4a5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'good': 0, 'rotten': 1}\n",
            "0\n",
            "Image: pear_1739689903499_jpg.rf.b685ec5423d93d08a7c83d440343afd7.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: pear_1739689905834_jpg.rf.017f9e037970f1ff157cf5e2e5a5b47a.jpg | True: good | Predicted: good | Confidence: 99.32% | Loss: 0.0068\n",
            "0\n",
            "Image: pear_1739689903073_jpg.rf.68de94ab205e55c0497b7f3d082b779f.jpg | True: good | Predicted: good | Confidence: 99.80% | Loss: 0.0020\n",
            "0\n",
            "Image: apple_1739689875759_jpg.rf.8ad9d8eafe8ce16eda2a9a39b2ef3b90.jpg | True: good | Predicted: good | Confidence: 90.84% | Loss: 0.0961\n",
            "0\n",
            "Image: banana_1739689929969_jpg.rf.426a8dbaa169e9ae46ca53bcb476288c.jpg | True: good | Predicted: good | Confidence: 99.95% | Loss: 0.0005\n",
            "0\n",
            "Image: banana_1739689929536_jpg.rf.c20a7efca61893e41b2538f169a287b1.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: kiwi_1739689838537_jpg.rf.81dfecf6e8207697262dcbeb11510f06.jpg | True: good | Predicted: good | Confidence: 99.90% | Loss: 0.0010\n",
            "0\n",
            "Image: apple_1739689875022_jpg.rf.de98e5cf5566d01f8c111fcde05fa411.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: apple_1739689876050_jpg.rf.7895eecedd36ada8b57e28ac3ebb6805.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: kiwi_1739689836152_jpg.rf.0f8c6450814978e04ee3f63167592f18.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: banana_1739689928029_jpg.rf.5f38da2b069943bdaf18f9dc7b4e2ff8.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689904631_jpg.rf.cb7d349059d23c273aab588b2e39d0cd.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: apple_1739689876334_jpg.rf.13688e613abb8cdf94a85da1afbd9bb1.jpg | True: good | Predicted: good | Confidence: 90.93% | Loss: 0.0951\n",
            "0\n",
            "Image: apple_1739689873489_jpg.rf.428523cb88b92b96ce6187b143ce8505.jpg | True: good | Predicted: good | Confidence: 99.65% | Loss: 0.0035\n",
            "0\n",
            "Image: kiwi_1739689836056_jpg.rf.e061977587a07140cca1e42d5afb7037.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689904431_jpg.rf.8b940ae877ef85a2704f9e933295491b.jpg | True: good | Predicted: good | Confidence: 99.94% | Loss: 0.0006\n",
            "0\n",
            "Image: apple_1739689875130_jpg.rf.a9c82256e3d71dbd6390724eeb2ada33.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: banana_1739689927327_jpg.rf.b528e73e547ff6cdfd2a20a7abc08df4.jpg | True: good | Predicted: good | Confidence: 99.88% | Loss: 0.0012\n",
            "0\n",
            "Image: kiwi_1739689838432_jpg.rf.ff87587b9f661336f5f493c186a0cacf.jpg | True: good | Predicted: good | Confidence: 99.91% | Loss: 0.0009\n",
            "0\n",
            "Image: banana_1739689926618_jpg.rf.8314efae315acc2cf8a050e3a5515648.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: kiwi_1739689834912_jpg.rf.52b35c6a848a48c0f104da7a4bf6450c.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: apple_1739689873593_jpg.rf.479a377bab1a07466ea78a7f1373cfa0.jpg | True: good | Predicted: good | Confidence: 90.36% | Loss: 0.1013\n",
            "0\n",
            "Image: pear_1739689905370_jpg.rf.16fc5413e80894bd9fd6936d2fa7de0c.jpg | True: good | Predicted: good | Confidence: 99.89% | Loss: 0.0011\n",
            "0\n",
            "Image: pear_1739689906649_jpg.rf.5f33b295a976a1a6f0ce34cd844c4636.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: starfruit_1739689943471_jpg.rf.d7b5feb5db639d2da7930fd57322aeeb.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: kiwi_1739689835200_jpg.rf.d911fcd17e7fa7e6e6e8a2717f86b155.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: kiwi_1739689835580_jpg.rf.bb6d080bbfb019aa64057dacf7d78158.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: starfruit_1739689947271_jpg.rf.fa93b0f2fadae725c949f8f298e12680.jpg | True: good | Predicted: good | Confidence: 99.97% | Loss: 0.0003\n",
            "0\n",
            "Image: apple_1739689874156_jpg.rf.878713ed3735f16d6b8b3f595eacf6a2.jpg | True: good | Predicted: good | Confidence: 98.15% | Loss: 0.0187\n",
            "0\n",
            "Image: pear_1739689903496_jpg.rf.18b427d848c8c03b46922383bb488c0a.jpg | True: good | Predicted: good | Confidence: 99.97% | Loss: 0.0003\n",
            "0\n",
            "Image: pear_1739689906751_jpg.rf.88c0161a82c2d84281a0be6d4a9d91d7.jpg | True: good | Predicted: good | Confidence: 99.78% | Loss: 0.0022\n",
            "0\n",
            "Image: apple_1739689872432_jpg.rf.69abd59d44f7e05a48de25cdff9a146a.jpg | True: good | Predicted: good | Confidence: 99.94% | Loss: 0.0006\n",
            "0\n",
            "Image: apple_1739689876243_jpg.rf.cc0a5963172c06f0c2527c886f7a22a8.jpg | True: good | Predicted: good | Confidence: 99.23% | Loss: 0.0077\n",
            "0\n",
            "Image: apple_1739689875959_jpg.rf.cb2e3f9b84edaa0f51be4a141819c8ae.jpg | True: good | Predicted: good | Confidence: 78.57% | Loss: 0.2412\n",
            "0\n",
            "Image: banana_1739689931046_jpg.rf.55db5c67f74a11396208c1ae1e2f7010.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: banana_1739689930731_jpg.rf.1e5147a5aa3254806e33a129752527e3.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: kiwi_1739689837764_jpg.rf.c45cc8e72154e1e4096c6411606ca118.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: starfruit_1739689946065_jpg.rf.71894564fd1a21a2614febeb7494754a.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: kiwi_1739689836688_jpg.rf.6116951836faa9baf72b70dbdf3b3a1f.jpg | True: good | Predicted: good | Confidence: 99.96% | Loss: 0.0004\n",
            "0\n",
            "Image: apple_1739689874250_jpg.rf.15aa655466601223ed88ed5ac3549237.jpg | True: good | Predicted: good | Confidence: 97.75% | Loss: 0.0228\n",
            "0\n",
            "Image: kiwi_1739689838329_jpg.rf.58e6ce253257a7959c2f320cd0857577.jpg | True: good | Predicted: good | Confidence: 99.91% | Loss: 0.0009\n",
            "0\n",
            "Image: kiwi_1739689835299_jpg.rf.85f146ef800233cd9351f7c9006fb897.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: starfruit_1739689944047_jpg.rf.1f8c05d18c13856415409b714715c337.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: starfruit_1739689947696_jpg.rf.b5cc37401132d5dd461d81a03e9983e7.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: apple_1739689875857_jpg.rf.16aab933c2dc05b308f07e9181862ac1.jpg | True: good | Predicted: good | Confidence: 99.89% | Loss: 0.0011\n",
            "0\n",
            "Image: starfruit_1739689946445_jpg.rf.283a6dcf02370e6b095e4c5ba4b5a6c3.jpg | True: good | Predicted: good | Confidence: 99.96% | Loss: 0.0004\n",
            "0\n",
            "Image: banana_1739689927743_jpg.rf.3dec0fcffb7dd53a850be4e7e92fb110.jpg | True: good | Predicted: good | Confidence: 99.54% | Loss: 0.0046\n",
            "0\n",
            "Image: apple_1739689873001_jpg.rf.80256daac87e290dea1a741352ce5350.jpg | True: good | Predicted: good | Confidence: 99.97% | Loss: 0.0003\n",
            "0\n",
            "Image: starfruit_1739689948348_jpg.rf.71fbfbe874a44382de8cc262923a93f1.jpg | True: good | Predicted: good | Confidence: 99.92% | Loss: 0.0008\n",
            "0\n",
            "Image: starfruit_1739689946449_jpg.rf.90490841f375d673023f6c178391052f.jpg | True: good | Predicted: good | Confidence: 99.94% | Loss: 0.0006\n",
            "0\n",
            "Image: kiwi_1739689836690_jpg.rf.634585fad3f8e6d91c6cc4c7adafa22d.jpg | True: good | Predicted: good | Confidence: 99.89% | Loss: 0.0011\n",
            "0\n",
            "Image: kiwi_1739689836058_jpg.rf.11c03f955bbf78e9f6c80b2c9b746a72.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: pear_1739689907272_jpg.rf.f59a5edf371ce487ea9c8dfafa922a31.jpg | True: good | Predicted: good | Confidence: 99.82% | Loss: 0.0018\n",
            "0\n",
            "Image: starfruit_1739689946069_jpg.rf.122e33db4d5943eeb711a91b08a3ff2e.jpg | True: good | Predicted: good | Confidence: 99.87% | Loss: 0.0013\n",
            "0\n",
            "Image: pear_1739689905007_jpg.rf.1d2afcbc41f7421a2ce037a74d722d57.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689874829_jpg.rf.273c8357e9c08543d84ac08566470219.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: pear_1739689905739_jpg.rf.b367ed1403e1214fe5ac6721db194081.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: pear_1739689907069_jpg.rf.31adda99505cd1e0027cac19cceabef7.jpg | True: good | Predicted: good | Confidence: 99.93% | Loss: 0.0007\n",
            "0\n",
            "Image: starfruit_1739689944885_jpg.rf.60c77ef4fba569d3cf380250198c637e.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: starfruit_1739689945084_jpg.rf.f9b77a66704aed5b33572bf53a14ebb7.jpg | True: good | Predicted: good | Confidence: 99.96% | Loss: 0.0004\n",
            "0\n",
            "Image: starfruit_1739689945874_jpg.rf.f33063a88a917a4d52dcb4a6987c291f.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: starfruit_1739689944367_jpg.rf.86960dd806a602584ec2004b41ce9267.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: pear_1739689906849_jpg.rf.d8524c949e56f03cd5b5e561a573d7b4.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: starfruit_1739689947046_jpg.rf.716eb6cea12256c6dae7c0c8d12f6b28.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689872909_jpg.rf.27f4d9c4a38e3db29eab639ece641943.jpg | True: good | Predicted: good | Confidence: 99.85% | Loss: 0.0015\n",
            "0\n",
            "Image: kiwi_1739689838234_jpg.rf.f1dc7cb659aab0bb8dffbe35e0310d69.jpg | True: good | Predicted: good | Confidence: 99.96% | Loss: 0.0004\n",
            "0\n",
            "Image: pear_1739689905191_jpg.rf.5be05f39af588570718a60b1c47a23dd.jpg | True: good | Predicted: good | Confidence: 99.97% | Loss: 0.0003\n",
            "0\n",
            "Image: pear_1739689907778_jpg.rf.a830ee37f7e81314791e2082a051d047.jpg | True: good | Predicted: good | Confidence: 99.95% | Loss: 0.0005\n",
            "0\n",
            "Image: apple_1739689873294_jpg.rf.a7ab5e9ddff384446ac7899f4bced6ec.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689872906_jpg.rf.0cd0c4ef67ad438c9bdf299d65b65666.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: kiwi_1739689837545_jpg.rf.37d9fd1f32fac4cff5800281fff732bd.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: starfruit_1739689945878_jpg.rf.b4cb87b1c18c7cc959376449b4eff0fd.jpg | True: good | Predicted: good | Confidence: 99.93% | Loss: 0.0007\n",
            "0\n",
            "Image: starfruit_1739689946828_jpg.rf.2d436b1233059634d32e638a60bcf968.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: kiwi_1739689837053_jpg.rf.0cec67681d40200d86811d3f562c9128.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689875455_jpg.rf.a05ddb12207de96275fcddfa17de305e.jpg | True: good | Predicted: good | Confidence: 99.92% | Loss: 0.0008\n",
            "0\n",
            "Image: pear_1739689907276_jpg.rf.0ccdb4d7d0e371317ffc71c7bd880191.jpg | True: good | Predicted: good | Confidence: 99.87% | Loss: 0.0013\n",
            "0\n",
            "Image: starfruit_1739689946063_jpg.rf.391e99022ddf9262422da9de1960da1e.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: kiwi_1739689835105_jpg.rf.82c5d07c589e37959abd460376e0ab92.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: starfruit_1739689944259_jpg.rf.c59c0f6f484bbe90092a029ad63f9477.jpg | True: good | Predicted: good | Confidence: 99.91% | Loss: 0.0009\n",
            "0\n",
            "Image: apple_1739689872908_jpg.rf.df47fc30350eccf304701677116fd4f3.jpg | True: good | Predicted: good | Confidence: 99.75% | Loss: 0.0025\n",
            "0\n",
            "Image: apple_1739689874451_jpg.rf.55cbce916dff254611522d16892ba3ff.jpg | True: good | Predicted: good | Confidence: 99.94% | Loss: 0.0006\n",
            "0\n",
            "Image: starfruit_1739689944782_jpg.rf.358e6486c944431860c91581483cbf2d.jpg | True: good | Predicted: good | Confidence: 99.79% | Loss: 0.0021\n",
            "0\n",
            "Image: kiwi_1739689834179_jpg.rf.cc3d14438d415c81273d0aa7b90e6ebf.jpg | True: good | Predicted: good | Confidence: 99.89% | Loss: 0.0011\n",
            "0\n",
            "Image: starfruit_1739689944480_jpg.rf.be32d67f723195bb07831397b5ba14ee.jpg | True: good | Predicted: good | Confidence: 99.96% | Loss: 0.0004\n",
            "0\n",
            "Image: banana_1739689928317_jpg.rf.dfb30ad6ff06e7990c9753d1410051e9.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689905460_jpg.rf.851e166337dd10d18423dcba7ec8e178.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689906847_jpg.rf.51700282ef92dbee662e46f1d0986195.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689906955_jpg.rf.4f7066a075060e5aa86f9893d47c4556.jpg | True: good | Predicted: good | Confidence: 99.71% | Loss: 0.0029\n",
            "0\n",
            "Image: pear_1739689906120_jpg.rf.c66302d09d18a1ea0adc6437942dfb7c.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689872429_jpg.rf.2b45e5f412cdcddd1c0808d80c529121.jpg | True: good | Predicted: good | Confidence: 98.92% | Loss: 0.0109\n",
            "0\n",
            "Image: banana_1739689928871_jpg.rf.f98ca388a73da4d24f8842f1965f1a16.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689905642_jpg.rf.1267fa1043d482f67e9333ce542fd6a1.jpg | True: good | Predicted: good | Confidence: 99.60% | Loss: 0.0040\n",
            "0\n",
            "Image: apple_1739689876429_jpg.rf.ee65696aa8aa4666fc35c136a1801640.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: apple_1739689876430_jpg.rf.7e6f202cb83a18b96e7e01a44c7529db.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: pear_1739689905554_jpg.rf.4f0f7b97c35d0c6a0e509ce1f998c2f6.jpg | True: good | Predicted: good | Confidence: 99.89% | Loss: 0.0011\n",
            "0\n",
            "Image: starfruit_1739689944883_jpg.rf.ef10bfc4d693dc3b8bcb4c360947d670.jpg | True: good | Predicted: good | Confidence: 99.97% | Loss: 0.0003\n",
            "0\n",
            "Image: starfruit_1739689946941_jpg.rf.8e5cff09c18e84a54719f86bafd9adaf.jpg | True: good | Predicted: good | Confidence: 99.95% | Loss: 0.0005\n",
            "0\n",
            "Image: kiwi_1739689835009_jpg.rf.11fb8296ee13de38dc8dee3142fdc7fa.jpg | True: good | Predicted: good | Confidence: 99.91% | Loss: 0.0009\n",
            "0\n",
            "Image: pear_1739689906541_jpg.rf.c057519f9779b5393dcefd9ff32bc95a.jpg | True: good | Predicted: good | Confidence: 99.62% | Loss: 0.0038\n",
            "0\n",
            "Image: starfruit_1739689943735_jpg.rf.83c37a1adbb4cea5f829643ba823490a.jpg | True: good | Predicted: good | Confidence: 99.83% | Loss: 0.0017\n",
            "0\n",
            "Image: kiwi_1739689835581_jpg.rf.91cc1c47431cf8354bf21d71923315e4.jpg | True: good | Predicted: good | Confidence: 99.95% | Loss: 0.0005\n",
            "0\n",
            "Image: banana_1739689930281_jpg.rf.619f960baf21b0cf8ecb1370021a66ae.jpg | True: good | Predicted: good | Confidence: 99.83% | Loss: 0.0017\n",
            "0\n",
            "Image: apple_1739689873595_jpg.rf.a537b12cb4535d1df9a4326641b6b476.jpg | True: good | Predicted: good | Confidence: 98.94% | Loss: 0.0106\n",
            "0\n",
            "Image: starfruit_1739689946258_jpg.rf.e2c25326aef4d3dfac74bbb31593e687.jpg | True: good | Predicted: good | Confidence: 99.87% | Loss: 0.0013\n",
            "0\n",
            "Image: banana_1739689926822_jpg.rf.1d29f29c0ad4c9e00aef04a56c081d00.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: banana_1739689927441_jpg.rf.9bc5f944c29e6efb441687c3ca8171cc.jpg | True: good | Predicted: good | Confidence: 99.60% | Loss: 0.0040\n",
            "0\n",
            "Image: apple_1739689873783_jpg.rf.8489e203620a3afe6fefc56c520e1227.jpg | True: good | Predicted: good | Confidence: 91.84% | Loss: 0.0851\n",
            "0\n",
            "Image: banana_1739689930286_jpg.rf.9b2072f64242887e457a5cdeaf99e547.jpg | True: good | Predicted: good | Confidence: 99.85% | Loss: 0.0015\n",
            "0\n",
            "Image: kiwi_1739689835486_jpg.rf.d4679b431172a12554918a45e80b6ab6.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689905098_jpg.rf.91cc88ae9c69e4adc2878dfa27bfadcd.jpg | True: good | Predicted: good | Confidence: 99.98% | Loss: 0.0002\n",
            "0\n",
            "Image: starfruit_1739689946633_jpg.rf.278fd47fbcd2b9ec303439ad133d860a.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: pear_1739689903712_jpg.rf.9cda2f09ea7ae1b75ccf2f89a327ea00.jpg | True: good | Predicted: good | Confidence: 99.99% | Loss: 0.0001\n",
            "0\n",
            "Image: apple_1739689874155_jpg.rf.30cdd0d104bafe9c86c915c547ed4107.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "0\n",
            "Image: apple_1739689875023_jpg.rf.375c5bdeb24d5e4c7df2f2d6eaeda4d1.jpg | True: good | Predicted: good | Confidence: 99.68% | Loss: 0.0032\n",
            "0\n",
            "Image: apple_1739689874832_jpg.rf.6fa138f5969ad44cbe8a2d8f58d2ae89.jpg | True: good | Predicted: good | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689772142_jpg.rf.d085588b22a4f789a2467ecbea5e5939.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689709992_jpg.rf.0bed1ba3251f9ca164714bb0fa5a15b0.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_33_jpeg.rf.13db73479a8a2ea69ec2df3b83b46460.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689737712_jpg.rf.3ad23c46958b4961f5c5656fab4987e1.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_1739689660504_jpg.rf.7d631b0e27e245b749f41fd93f192b39.jpg | True: rotten | Predicted: rotten | Confidence: 98.38% | Loss: 0.0163\n",
            "1\n",
            "Image: kiwi_1739689772536_jpg.rf.0e113eee79748f645d0ec94fe3ab2240.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689741941_jpg.rf.2e8fe56a99480ff1dfe35cab5e94a75d.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: start_r_9_webp.rf.9d959b78740a56f538a3278b58aa3d86.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_44_jpg.rf.edcbe14ac47828c43724d6e1a8afd82c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_15_webp.rf.0fa16db5767a43ce43ad4681f77ef40c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_41_webp.rf.f1f66f0df1b118844dc426994edfce75.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689773853_jpg.rf.dff2a64259bf0e11b0bf19318d4631f5.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_32_jpg.rf.f7c6799c232de98d62593009d9f94109.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_34_webp.rf.99761828d068f68aacfdb61124af28b1.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_r_13_avif.rf.617facb5d6ed7f7a60fee22c3b33495b.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_22_jpeg.rf.2e138045afa84057ddc2ddd40696dc67.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_r_6_webp.rf.33fe172bd6133ee3d93a1e1bef9f2d20.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_03_webp.rf.9e9049832b81d64193050a1e1e3f9ace.jpg | True: rotten | Predicted: rotten | Confidence: 99.99% | Loss: 0.0001\n",
            "1\n",
            "Image: kiwi_1739689775464_jpg.rf.f524619f2daa05956971cb511bce920c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689739895_jpg.rf.cf8a3bfb2a11ef722d15b74c2f12054e.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689742456_jpg.rf.2944aac41e77a850301007e2f1c4015c.jpg | True: rotten | Predicted: rotten | Confidence: 99.99% | Loss: 0.0001\n",
            "1\n",
            "Image: banana_1739689739008_jpg.rf.8177601bed4089751a241e3c623b9be3.jpg | True: rotten | Predicted: rotten | Confidence: 99.99% | Loss: 0.0001\n",
            "1\n",
            "Image: apple_r_10_webp.rf.f3974292fb0eb56ab2de4cc3707c75ed.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689774655_jpg.rf.05c897d8622dcba2aa45695b1f424df0.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689775361_jpg.rf.6c160ae5b652b4cdcda2fe4f64ffe27b.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_1739689773766_jpg.rf.3c2de70b8d9a389c8f35a3352582bae5.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689660503_jpg.rf.51e121f4bd61a64b6ce0368c3bb86db0.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689740526_jpg.rf.d5be011210d29ac7b7387cff9d13118c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_1739689660604_jpg.rf.8c766b9d88fb1a5fddc5af94e0f95677.jpg | True: rotten | Predicted: rotten | Confidence: 99.99% | Loss: 0.0001\n",
            "1\n",
            "Image: kiwi_1739689708343_jpg.rf.86cf397788e7f323993899e510ce11ad.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689776621_jpg.rf.2ece544bf32d872e75a00a528de52fd7.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_1739689660992_jpg.rf.b1f8de8fdcd5acbb07ea9e21b6c0dd69.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_17_webp.rf.1aafdf09e1f7f74464dfbf6d396a1f8e.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: start_r_16_webp.rf.50efcfe8448df779407a14cf4cd35477.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689740610_jpg.rf.a2edd3e73d1917eac85a5a211ddf3aad.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_42_webp.rf.fcb82bcbe2f8a8775742f84891986418.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: starfruit_1739689709447_jpg.rf.25cc99f62bf042aa56161380bf9fa9c9.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689742874_jpg.rf.0e03e8b190316b7599f3dfcc11f34d41.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_1739689685545_jpg.rf.614d7cf4d01b6e241f398e2559443501.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689742251_jpg.rf.18688564f60c409839c06363299f59e6.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_02_webp.rf.73935df5240233f8a750cb65a2ebba6d.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_38_jpg.rf.9eaa7765666f6cfd21738e9853a5a400.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689739414_jpg.rf.2858a1893cde7ec771b88de7020b052c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_r_49_jpg.rf.f0483aa56847f0ae871dd6301486d2c5.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: start_r_19_webp.rf.447e961e749c55d5873f4b0538edcb60.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689741950_jpg.rf.eeceaaae40e1285098b661818941133e.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_1739689741945_jpg.rf.8c36ef9d4a28ec2691721009a0abe6a8.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: apple_1739689661466_jpg.rf.6b8caac2d02244a617935ab90808c9d1.jpg | True: rotten | Predicted: rotten | Confidence: 80.49% | Loss: 0.2170\n",
            "1\n",
            "Image: banana_r_47_jpg.rf.87711d2b9ad7b7585d92a78077b1b662.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_39_jpg.rf.4342d932915177eff8697331d3b1bab8.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_r_17_jpg.rf.49683582bc6e2c4350d32dc6e74e0c78.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_r_20_webp.rf.3b5d2e02c66ccad43a2062bebcc6c66d.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_r_7_jpeg.rf.e9244ffc77c53be08e698d69b8b17a32.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_1739689685059_jpg.rf.a982d5364f2684f934690e3826a3aee8.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_15_webp.rf.92e5c606a5805f32794f5e36fba8639d.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: kiwi_1739689775864_jpg.rf.ed7518718f9e2d87840e4426df9c2d72.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: pear_r_9_avif.rf.25e5c5cb9b76e666fc486bd2975fe92c.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "1\n",
            "Image: banana_r_17_jpeg.rf.6432f2927fee12f66767ac0e33ad352a.jpg | True: rotten | Predicted: rotten | Confidence: 100.00% | Loss: 0.0000\n",
            "Predictions saved to /content/prediction_results.txt\n",
            "True Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Class Names Mapping: {'good': 0, 'rotten': 1}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       1.00      1.00      1.00       115\n",
            "      rotten       1.00      1.00      1.00        58\n",
            "\n",
            "    accuracy                           1.00       173\n",
            "   macro avg       1.00      1.00      1.00       173\n",
            "weighted avg       1.00      1.00      1.00       173\n",
            "\n",
            "\n",
            "Test Loss: 0.0058\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}